<!DOCTYPE html>
<meta charset="utf-8"/>

<title>데이터 분석 방법론에 대한 고찰</title>


<h2 id="1">1. 설명변수(기간)에 어떤 방식으로 가중치를 부여하는 것이 효과적인가</h2>

<style>
#example {
    background-color: #f1f1f1;
    padding: 0.01em 16px;
    margin: 20px 0;
    box-shadow: 0px 2px 4px 0px rgba(0,0,0,0.16), 0px 2px 10px 0px rgba(0,0,0,0.12) !important;
}
</style>

<div id = "example">
  <p>머신러닝의 강점은, 데이터 기반 통계/확룔 학습을 통해 추출한 최적의 가중치를 모델링에 사용하는 것으로, 성능을 위해 임의로 데이터를 조작할(가중치를 부여할) 필요가 없음. 다만, <strong>학습 과정의 파라미터를 조정하며</strong> 보다 높은 성능을 이끌어 낼 수 있는 모델과 가중치를 찾아낼 수 있음</p>
</div>

<p><br/></p>

<p>설명 변수에 가중치를 부여하는 방법은 샘플링(관점A), 또는 변수 조정(관점B)을 통해 검토해 볼 수 있음</p>

<h3 id="a">관점 A- 어떠한 가중치로 훈련데이터를 선별할 것인지</h3>

<ul>
<li><p>특정 기간의 데이터만 가중치를 두고 샘플링 하는 것은 학습 과정에서 보다 높은 성능을 나타낼 수 있지만, 실제 수요 예측을 하는 경우 편향된 결과치를 예측할 수가 있음 (불안정적)</p></li>

<li><p>SKU 마다 각자 수요의 특성은 다르겠지만, 1년 주기로 계절성을 (유사한 형태를) 띄는 경우가 통상적</p></li>

<li><p>이같은 경우 모델링 성능을 위해 1년 미만의 데이터를 샘플링하여 수요 예측에 사용하는 경우, SKU의 수요 특성을 백분 반영할 수 없음 (마치 다섯 장님이 각자 코끼리를 만지고 설명하는 것과 비슷한 케이스)</p></li>

<li><p>예시를 위해 삼각함수로 생성한 아래의 데이터로 간단한 테스트 시행:</p>

<p><img src="fig-1.png" alt="fig-1" /></p></li>

<li><p>위의 그래프는 &fnof;(x) = ax+bx<sup>2</sup>+cx<sup>3</sup> + e 형태의 간단한 모델에서 샘플링에 따른 성능 테스트를 나타냄</p></li>

<li><p>빨간 선은 임의로 샘플링하여 데이터의 대표성을 나타낸다고 보기 어렵고, 파란 선은 그나마 데이터의 특성을 상당히 반영할 수 있을 만큼 샘플링하여 모델 적합</p></li>

<li><p>훈련데이터와 이웃한 데이터에서는 두 모델 간 예측의 편차가 크게 발생하지 않으나, 빨간색 모델은 멀어질수록 편차가 크게 발생</p></li>
</ul>

<p>그럼에도 불구하고, 미지의 데이터를 가지고 수요를 예측할 때 파란색처럼 가용 데이터를 최대한 훈련데이터로 활용하는 것이 무조건적으로 더 나은 성능을 보장한다고 보기는 어려움. 과적합의 문제도 있지만 실제로 빨간색의 훈련데이터가 변화하는 미래 수요나 트렌드에 더 적합할 가능성도 배제할 수 없음. "샘플링을 제대로 하지도 못하며서 그냥 데이터만 막 들이밀면 문제가 잘 해결될 것 처럼 말하지 말라!" 라는 말을 종종 들을 수도 있지만, 미래 수요 예측을 하는데 있어 샘플링을 통한 <strong>직관의 개입을 허용하기 보다는</strong>, 가용한 데이터는 백분활용하되 객관적인 통계/확률 기법으로 추출한 <strong>객관적 가중치를 바탕으로 예측</strong>을 하는 것이 시스템 측면에서 안정적인 결과값으로 이어지지 않을까 생각함.</p>

<p><br/></p>

<h3 id="b">관점 B - 어떠한 방식으로 변수 자체에 가중치를 더하여 성능 개선이 가능한지</h3>

<ul>
<li><p>위에서 언급한 바와 같이 머신러닝의 강점은 통계/확률 학습을 통해 최적의 가중치를 찾는 데 있음</p></li>

<li><p>사람이 직접 변수에 가중치를 부여하는 것은 주관적 판단을 모델링에 개입시키는 것으로, 가중치를 부여할만한 명백한 근거가 바탕되지 않는다면 임의로 데이터를 조정하는 것은 바람직하지 않음</p></li>

<li><p>다만 모델링에 앞서 두가지 방식으로 성능 개선을 모색해 볼 수 있을 것:</p>

<p>1) 변수 생성/변형</p>

<ul>
<li>예측하고자 하는 현상을 설명할 수 있는 다른 변수(feature)를 생성하거나 조합하여 설명력을 높일 수 있음. 단, 새로운 변수가 기존 변수와 높은 상관성을 나타내거나 예측 현상과 개연성이 떨어지는 노이즈에 지나치지 않는다면  오히려 역효과가 날 수 있음</li>

<li>혹은 데이터 특성이나 분석 목적에 적합한 모델을 학습하기 위하여 데이터를 구조적으로 변경할 필요가 있음 (예를 들어 연속형 데이터를 범주형 데이터나 가변수로 변형)</li>

<li>후자의 경우 결과적으로 변수 생성/변형에 따른 성능개선이라기 보다는 모델 변경에 따른 성능개선으로 볼 수 있음</li></ul>

<p>2) 학습 과정에 가중치(파라미터 조정) 부여</p>

<ul>
<li>최적의 가중치를 찾는 학습 과정은 기울기, 시뮬레이션 등 다양한 방식을 통해 모델의 성능을 개선시킴</li>

<li>예를 들어 선형 회귀 모델에서 정규화를 (계수 크기 제한) 통해 성능을 향상시키는 Ridge/Lasso/Elastic 모델은, 패널티를 부여하는 가중치 &alpha;를 사용자가 직접 설정하며 모델링을 개선</li></ul></li>
</ul>

<p><br/></p>

<hr />

<h2 id="2">2. 왜 비선형 모델을 사용하였고 우수한 성능을 보이는 이유는 무엇인가?</h2>

<div id="example">
  <p>결정트리 기반 비선형 머신러닝 모델은 판별 기준이 비선형적인 모습을 띄기 때문에 데이터 레이블이 변수 간에 불규칙하게 분포되어 있는 현대 데이터 특성에 선형 모델에 비해 더 적합하다고 생각하며, 시뮬레이션을 통해 학습하는 앙상블 기법들의 등장으로 과적합에 효과적으로 대응하며 트리기법의 가장 큰 단점인 성능을 개선을 기대할 수 있음</p>
</div>

<p><br/></p>

<ul>
<li><p>전통적인 선형 모델에 비하여 비선형 모델(트리)이 갖는 장점들은 다음과 같음:</p>

<p>1) 결정경계가 (판별 기준이) 선형이 아니기 때문에 <strong>불규칙적인 오늘날 현상들과 데이터 세트에 부합</strong></p>

<p>2) 조건 판단에 따라 분류/회귀하기 때문에 변수 튜닝이나 정규화에 대한 필요가 없음(적음) </p>

<p>3) 변수 간 독립성을 가정하는 선형모델과 비교, 다중공선성에 견고하고 안정적임</p></li>

<li><p>문제는 그럼에도 불구하고 결정트리 모델의 성능이 저조하다는 데에 있고, 이는 훈련데이터에 과적합하게 되어 예측에 부적합한 모습을 띄기 때문</p></li>

<li><p>단점 개선을 위해 다양한 시도들이 있었고, 그중 하나가 강력해진 컴퓨팅 파워를 통해 <strong>여러개의 결정트리 모델을 시뮬레이션 하고, 가중 평균하여 강력한 하나의 보편적인 모델을 만드는 앙상블 기법임</strong></p>

<p><img src="https://swalloow.github.io/assets/images/agg_result.png" alt="" /></p>

<p><br/></p></li>

<li><p>트리 기반 앙상블 모델 중 하나인 랜덤포리스트의 경우 각 결정트리의 파라미터 값을 조율하기는 하지만, 기본적으로 여러개의 훈련데이터 세트로 여러개의 트리를 만들어 평균내는 모델로, 이정도만으로도 눈에 띄게 예측성능 향상을 기대할 수 있음</p></li>

<li><p>또 다른 트리 기반 앙상블 모델인 부스팅은, 랜덤포레스트와 비슷하지만 자주 틀리는 데이터에 가중치를 두고 샘플링하여 학습을 반복하는 일련의 시뮬레이션을 반복하며 성능을 개선</p></li>

<li><p>실제 그래디언트 부스팅 트리는 캐글같은 머신러닝 대회에서 여러차례 우승도 차지할 정도로 널리 사용하는 기법 중 하나로, 머신러닝 기법 중 높은 성능을 인정받음</p></li>

<li><p>본인도 과거 화장품 수요예측에서 파라미터 튜닝 전 xgboosting이 86%, Bayesian Hierarchical Regression이 83% 수요 예측 정확도(MAPE)를 기록하며 부스팅 기법의 우수한 성능을 경험</p></li>
</ul>

<p><br/></p>

<hr />

<h2 id="3sku">3. SKU 별로 각기 다른 모델을 사용하는 것이 정말 효율적인가?</h2>

<div>
  <p>SKU 별 최적의 모델은 보편적인 상황에서 최고의 성능을 보일 가능성이 가장 높은 것이지, 항상 다른 모델보다 좋은 성능을 보이는 것은 아님. 따라서 모든 SKU에 대하여 각기 다른 모델을 사용하는 것은 비용 대비 효율적이라고 보기에는 어려움.</p>
</div>

<p><br/></p>

<ul>
<li><p>성능 측면에서만 이야기를 한다면, 당연히 SKU 별로 최적의 모델을 사용하는 것이 높은 예측정확도를 보일 것</p></li>

<li><p>여기서 최적의 모델이란 training/validation set에서 가장 예측정확도가 높은 모델이고, 위 모델의 '최종 성능'은 test set에 대해 예측한 결과일 것</p></li>

<li><p>위 프로세스를 간단히 정리해 보자면 다음과 같음:</p>

<p>1) 데이터를 <code>training</code> / <code>validation</code> / <code>test</code> 로 구분</p>

<p>2) training set로 여러 종류의 예측 모델들을 생성</p>

<p>3) validation set로 2)에서 생성한 모델들의 성능 비교</p>

<p>4) validation set 하에서 가장 예측 정확도가 높은 모델 채택 및 개선</p>

<p>5) 미지의 test set으로 예측정확도를 산출하여 모델의 보편적인 '최종 성능' 평가</p>

<p>6) SKU 별로 위의 작업 반복</p></li>

<li><p>결국 어떤 SKU와 최적의 모델의 '최종 성능'이라는 것은 <strong>test set 안에서의 예측 정확도</strong>임</p></li>

<li><p>달리 얘기하자면, 최적의 모델은 미지의 데이터에 대해서 '최종 성능' 수준의 우수한 예측 정확도를 보일 가능성이 가장 높지만, 다른 예측 모델이 '최종 성능'보다 높은 예측 정확도를 보일 여지도 분명히 있음</p></li>

<li><p>실제로 위 설명을 반증하는 것이, 별로라고 생각했던 예측 모델이 운이 좋게 매우 높은 예측 성능을 보이는 경우가 종종 있음</p>

<p><br/></p></li>

<li><p>그렇다면, 실제 수요예측을 할 때 미지의 데이터에 대해서 '최종 성능'을 보장할 수 없는 모델링을 SKU 별로 진행 할 필요가 있을까?란 의문이 들수밖에 없음</p></li>

<li><p>이는 어느 정도까지 효율성보다 효과에 무게를 둘지 정책적으로 판단할 문제라고 생각함</p></li>

<li><p>다만 효율성에 무게를 두기로 결정한다면, 다음과 같은 방법을 제안할 수 있음:</p>

<p>1) 중요한 SKU에 대해서는 SKU 별 예측 모델 사용</p>

<ul>
<li>중요하다는 기준은 애매모호할 수 있으므로 판매 수량 상위 n%, 혹은 차원축소 기법(PCA)을 활용하여 데이터 기반 기준 수립</li></ul>

<p>2) 그 외에는 카테고리 별 예측 모델 사용</p>

<ul>
<li>여기서도 마찬가지로 상품군에 따라 사전에 정의해 둔 카테고리를 따를 수도 있지만 K-means, DBSCAN 등 비지도 학습을 통해 상위 클러스터를 정의할 수도 있음</li></ul></li>

<li><p>이 경우, 하나의 수요예측 모델로 여러 SKU의 수요를 예측하는 만큼 높은 수준의 예측 정확도를 보일 가능성은 상대적으로 낮을 수 있으나, 역설적으로 수요예측 모델을 고도화 하는데 리소스를 집중할 수 있음</p></li>
</ul>

<hr />

<p>참조. </p>

<p>https://3months.tistory.com/118</p>

<p>https://tensorflow.blog/%ED%8C%8C%EC%9D%B4%EC%8D%AC-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/2-3-6-%EA%B2%B0%EC%A0%95-%ED%8A%B8%EB%A6%AC%EC%9D%98-%EC%95%99%EC%83%81%EB%B8%94/</p>

<p>https://swalloow.github.io/bagging-boosting</p>

<p>https://developers.google.com/machine-learning/crash-course/glossary?hl=ko#sparse_features</p>

<p>https://www.slideshare.net/freepsw/boosting-bagging-vs-boosting</p>